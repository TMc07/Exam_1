{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsNntxTo8DEB"
      },
      "outputs": [],
      "source": [
        "!pip install pandas GitPython scikit-learn causalinference matplotlib numpy statsmodels seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/Final_For_.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqaz3Du28GqH",
        "outputId": "6a8e77e6-76ba-4a37-a95b-377d2e6bc518"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/Final_For_.ipynb to html\n",
            "[NbConvertApp] Writing 622805 bytes to /content/Final_For_.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from git import Repo\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from causalinference import CausalModel\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "# Suppress FutureWarnings from NumPy\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "#This was to save graphs into a single folder on my end\n",
        "directory_path = r\"C:\\Users\\tymcc\\OneDrive\\Desktop\\470_Project\\Mexico_Project\\Graphs\"\n",
        "\n",
        "# Clone the repository\n",
        "repo_url = \"https://github.com/TMc07/Exam_1.git\"\n",
        "\n",
        "# Define the path to the CSV files\n",
        "local_dir = \"Econ_470\"  # Existing directory with the cloned repository\n",
        "concen_path = 'Concen.csv'\n",
        "hogares1_path = 'hogares1.csv'\n",
        "Poblacion_path = 'Poblacion.csv'\n",
        "\n",
        "# Load the CSV files\n",
        "concen_df = pd.read_csv(concen_path)\n",
        "hogares1_df = pd.read_csv(hogares1_path)\n",
        "Poblacion_df = pd.read_csv(Poblacion_path)\n",
        "# Merge the dataframes on 'folio'\n",
        "merged_df = pd.merge(concen_df, hogares1_df, on='folio')\n",
        "merged_df2 = pd.merge(merged_df, Poblacion_df, on='folio')\n",
        "# Save the merged dataframe to a new CSV file\n",
        "merged_df2.to_csv(\"merged_data2.csv\", index=False)\n",
        "\n",
        "shortened = merged_df2.head()\n",
        "shortened.to_csv(\"shortened.csv\", index=False)\n",
        "\n",
        "merged_df_cleaned = merged_df2.dropna()\n",
        "merged_df_cleaned.to_csv(\"merged_df_cleaned.csv\", index=False)\n",
        "\n",
        "# Define the list of variables to keep\n",
        "variables_to_keep = ['folio', 'edad_y', 'beca', 'ed_formal', 'edocony', 'tot_resi', 'p0a11', 'ingtot', 'medica', 'medica_binned']\n",
        "\n",
        "#Binning of Medica into 100 bins using quartiles\n",
        "merged_df2['medica_binned'] = pd.qcut(merged_df2['medica'], q=100, labels=False, duplicates='drop')\n",
        "\n",
        "# Create a new DataFrame containing only the specified variables\n",
        "df_subset = merged_df2[variables_to_keep]\n",
        "df_Scholarship = df_subset[df_subset['beca'] == '6']\n",
        "\n",
        "# Display the new DataFrame\n",
        "df_subset.to_csv(\"df_subset.csv\", index=False)\n",
        "df_Scholarship.to_csv(\"df_Scholarship.csv\", index=False)\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('df_subset.csv')\n",
        "\n",
        "# Trim whitespace and replace empty strings or spaces in 'beca' with NaN\n",
        "df['beca'] = df['beca'].str.strip().replace('', np.nan).replace(' ', np.nan)\n",
        "df['edocony'] = df['edocony'].str.strip().replace('', np.nan).replace(' ', np.nan)\n",
        "\n",
        "# Convert 'beca' to numeric\n",
        "df['beca'] = pd.to_numeric(df['beca'], errors='coerce')\n",
        "\n",
        "# Drop rows where 'beca' is NaN\n",
        "df.dropna(subset=['beca'], inplace=True)\n",
        "df.dropna(subset=['edocony'], inplace=True)\n",
        "\n",
        "# Select the treatment and covariates\n",
        "treatment = 'beca'\n",
        "covariates = ['ed_formal', 'edocony', 'tot_resi', 'p0a11', 'edad_y']\n",
        "\n",
        "# Define treatment: 1 if 'beca' equals 6, 0 otherwise\n",
        "df['treatment'] = np.where(df['beca'] == 6, 1, 0)\n",
        "\n",
        "\n",
        "# Create a logistic regression model for propensity score estimation\n",
        "logistic = LogisticRegression()\n",
        "propensity_score = logistic.fit(df[covariates], df['treatment']).predict_proba(df[covariates])[:, 1]\n",
        "df['propensity_score'] = propensity_score\n",
        "\n",
        "\n",
        "# Perform nearest neighbor matching\n",
        "causal = CausalModel(\n",
        "    Y=df['ingtot'].values,\n",
        "    D=df['treatment'].values,\n",
        "    X=df['propensity_score'].values\n",
        ")\n",
        "causal.est_via_matching(bias_adj=True)\n",
        "\n",
        "# Assess balance by comparing means and distributions\n",
        "print(\"Balance Table Before Matching With no Normal Adjustments:\")\n",
        "print(causal.summary_stats)\n",
        "\n",
        "print(\"\\nBalance Table After Matching With no Normal Adjustments:\")\n",
        "print(causal.estimates)\n",
        "\n",
        "# Create a copy of the DataFrame to hold standardized values\n",
        "df_standardized = df.copy()\n",
        "\n",
        "# Standardize covariates\n",
        "scaler = StandardScaler()\n",
        "df_standardized[covariates] = scaler.fit_transform(df[covariates])\n",
        "\n",
        "# Create a logistic regression model for propensity score estimation\n",
        "logistic = LogisticRegression()\n",
        "propensity_score = logistic.fit(df_standardized[covariates], df_standardized['treatment']).predict_proba(df_standardized[covariates])[:, 1]\n",
        "df_standardized['propensity_score'] = propensity_score\n",
        "\n",
        "# Perform nearest neighbor matching\n",
        "causal = CausalModel(\n",
        "    Y=df_standardized['ingtot'].values,\n",
        "    D=df_standardized['treatment'].values,\n",
        "    X=df_standardized['propensity_score'].values\n",
        ")\n",
        "causal.est_via_matching(bias_adj=True)\n",
        "\n",
        "# Assess balance by comparing means and distributions\n",
        "\n",
        "print(\"\\nBalance Table After Matching:\")\n",
        "print(causal.estimates)\n",
        "\n",
        "# Logistic regression for treatment\n",
        "logit_model = sm.Logit(df_standardized['treatment'], sm.add_constant(df_standardized[covariates]))\n",
        "logit_result = logit_model.fit()\n",
        "print(\"\\nLogistic Regression for Treatment:\\n\")\n",
        "print(logit_result.summary())\n",
        "\n",
        "# Linear regression for outcome\n",
        "linear_model = sm.OLS(df_standardized['ingtot'], sm.add_constant(df_standardized[covariates + ['treatment']]))\n",
        "linear_result = linear_model.fit()\n",
        "print(\"\\nLinear Regression for Outcome:\\n\")\n",
        "print(linear_result.summary())\n",
        "\n",
        "def save_propensity_score_plots(df, treatment, output_dir):\n",
        "    # Set style for seaborn\n",
        "    sns.set(style=\"whitegrid\")\n",
        "\n",
        "    # Histogram/Density Plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(df[df[treatment] == 1]['propensity_score'], color=\"skyblue\", label='Treatment', kde=True)\n",
        "    sns.histplot(df[df[treatment] == 0]['propensity_score'], color=\"red\", label='Control', kde=True)\n",
        "    plt.title('Propensity Score Distribution by Treatment Group')\n",
        "    plt.xlabel('Propensity Score')\n",
        "    plt.ylabel('Density')\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"{output_dir}/Propensity_Score_Distribution.png\")\n",
        "    plt.close()\n",
        "\n",
        "def save_propensity_score_scatter_plot(df, treatment, medica_col, output_dir):\n",
        "    # Scatter Plot with 'medica' as y-axis\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plot treatment group\n",
        "    plt.scatter(df[df[treatment] == 1]['propensity_score'],\n",
        "                df[df[treatment] == 1][medica_col],\n",
        "                alpha=0.2, color=\"skyblue\", label='Treatment')\n",
        "\n",
        "    # Plot control group\n",
        "    plt.scatter(df[df[treatment] == 0]['propensity_score'],\n",
        "                df[df[treatment] == 0][medica_col],\n",
        "                alpha=0.2, color=\"red\", label='Control')\n",
        "\n",
        "    plt.title('Propensity Score vs. Medica by Treatment Group')\n",
        "    plt.xlabel('Propensity Score')\n",
        "    plt.ylabel(medica_col)\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"{output_dir}/Propensity_Score_vs_Medica_Scatter.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Usage\n",
        "save_propensity_score_plots(df, 'treatment', directory_path)\n",
        "save_propensity_score_scatter_plot(df, 'treatment', 'medica', directory_path)\n",
        "\n",
        "# Log-transform only the 'ingtot' variable\n",
        "df['ingtot_log'] = np.log(df['ingtot'] + 1)  # Adding 1 to avoid log(0)\n",
        "\n",
        "# Check and ensure that 'treatment' column exists in your DataFrame\n",
        "if 'treatment' in df.columns:\n",
        "    # Define 'medica_prop' before filtering and plotting\n",
        "    df['medica_prop'] = df['medica'] / df['ingtot']\n",
        "    df = df[df['medica'] != 0]  # Removing 'medica' values of 0\n",
        "\n",
        "\n",
        "    # Separate assignments for Oportunidades and Seguro Popular\n",
        "    df['assigned_to_oportunidades'] = df['beca'] == 6\n",
        "    df['assigned_to_seguro_popular'] = df['tot_resi'] > 5\n",
        "\n",
        "    # Filtering for different groups\n",
        "    oportunidades_df = df[df['assigned_to_oportunidades']]\n",
        "    seguro_popular_df = df[df['assigned_to_seguro_popular']]\n",
        "\n",
        "    # Calculating 'medica_prop' for both groups\n",
        "    oportunidades_df.loc[:, 'medica_prop'] = oportunidades_df['medica'] / oportunidades_df['ingtot']\n",
        "    seguro_popular_df.loc[:, 'medica_prop'] = seguro_popular_df['medica'] / seguro_popular_df['ingtot']\n",
        "\n",
        "\n",
        "    # Plotting the proportion of 'medica' vs. logged 'ingtot' for both groups\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.lineplot(x='ingtot_log', y='medica_prop', data=oportunidades_df, label='Oportunidades')\n",
        "    sns.lineplot(x='ingtot_log', y='medica_prop', data=seguro_popular_df, label='Seguro Popular')\n",
        "    plt.title('Medica Proportion vs. Logged Income for Oportunidades and Seguro Popular Groups')\n",
        "    plt.xlabel('Logged Income (ingtot)')\n",
        "    plt.ylabel('Proportion of Medica')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "else:\n",
        "    print(\"'treatment' column not found in the DataFrame.\")\n",
        "\n",
        "# Summary statistics for 'medica_prop' in Oportunidades group\n",
        "oportunidades_summary = oportunidades_df['medica_prop'].describe()\n",
        "\n",
        "# Summary statistics for 'medica_prop' in Seguro Popular group\n",
        "seguro_popular_summary = seguro_popular_df['medica_prop'].describe()\n",
        "\n",
        "# Separate data for 'assigned_to_oportunidades' and 'assigned_to_seguro_popular'\n",
        "oportunidades_data = df[df['assigned_to_oportunidades']]\n",
        "seguro_popular_data = df[df['assigned_to_seguro_popular']]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='ingtot_log', y='medica_prop', data=oportunidades_data, color='blue', label='Oportunidades')\n",
        "sns.scatterplot(x='ingtot_log', y='medica_prop', data=seguro_popular_data, color='red', label='Seguro Popular')\n",
        "plt.xlabel('Log of Total Income (ingtot_log)')\n",
        "plt.ylabel('Medical Proportion (medica_prop)')\n",
        "plt.ylim(0, 0.1)  # Keeping the y-axis limit\n",
        "plt.xlim(6, 14)\n",
        "plt.title('Comparison of Medical Proportion vs Total Income')\n",
        "plt.legend()\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig('medical_proportion_vs_income.png')  # Adjust the file path as needed\n",
        "\n",
        "# Separate data for 'assigned_to_oportunidades' and 'assigned_to_seguro_popular'\n",
        "oportunidades_data = df[df['assigned_to_oportunidades']]['ingtot_log']\n",
        "seguro_popular_data = df[df['assigned_to_seguro_popular']]['ingtot_log']\n",
        "\n",
        "# Plotting the cumulative distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.ecdfplot(oportunidades_data, label='Oportunidades', color='blue')\n",
        "sns.ecdfplot(seguro_popular_data, label='Seguro Popular', color='red')\n",
        "plt.xlabel('Medical Proportion (ingtot_log)')\n",
        "plt.ylabel('Cumulative Distribution')\n",
        "plt.title('Cumulative Distribution of Medical Proportion')\n",
        "plt.legend()\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig('medical_proportion_cumulative_distribution.png')  # Adjust the file path as needed\n",
        "\n",
        "\n",
        "def save_medica_prop_cumulative_distribution(df, output_dir):\n",
        "    # Setting seaborn style\n",
        "    sns.set(style=\"whitegrid\")\n",
        "\n",
        "    # Separate data for 'assigned_to_oportunidades' and 'assigned_to_seguro_popular'\n",
        "    oportunidades_data = df[df['assigned_to_oportunidades']]['ingtot_log']\n",
        "    seguro_popular_data = df[df['assigned_to_seguro_popular']]['ingtot_log']\n",
        "\n",
        "    # Plotting the cumulative distribution\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.ecdfplot(oportunidades_data, label='Oportunidades', color='blue')\n",
        "    sns.ecdfplot(seguro_popular_data, label='Seguro Popular', color='red')\n",
        "    plt.xlabel('Medical Proportion (ingtot_log)')\n",
        "    plt.ylabel('Cumulative Distribution')\n",
        "    plt.title('Cumulative Distribution of Medical Proportion')\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "    # Save the plot to the specified directory\n",
        "    plt.savefig(f\"{output_dir}/Medical_Proportion_Cumulative_Distribution.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Usage\n",
        "# Assuming 'df' is your DataFrame and 'directory_path' is the path to the directory where you want to save the plot\n",
        "save_medica_prop_cumulative_distribution(df, directory_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "oYT_U_rQ8Jno"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}